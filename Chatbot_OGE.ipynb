{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzmlJuou0LD4Rke0xAHny6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TMMichaelsen/AI_Chatbot/blob/main/Chatbot_OGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot de Atendimento - Ouvidoria-Geral do Estado de Minas Gerais"
      ],
      "metadata": {
        "id": "zOQfeCb03oZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instala√ß√£o do SDK Google"
      ],
      "metadata": {
        "id": "ADHtXsWG3h14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tbs0C2tm3MV8"
      },
      "outputs": [],
      "source": [
        "# Instala√ß√£o do pacote de IA Generativa\n",
        "!pip install -U -q google-generativeai\n",
        "\n",
        "# Importa√ß√£o das bibliotecas utilizadas\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Configura√ß√£o da API\n",
        "GOOGLE_API_KEY = userdata.get('API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configura√ß√µes do Modelo Generativo"
      ],
      "metadata": {
        "id": "D6YfYd9X5MwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Listando os modelos generativos dispon√≠veis\n",
        "\n",
        "print('Modelos Generative:\\n')\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "ia4f_0Qb46AW",
        "outputId": "302aae9b-e224-4b7c-d2e1-de1052dccfd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos Generative:\n",
            "\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√£o do modelo\n",
        "\n",
        "gen_model_name = 'gemini-1.5-pro-latest'\n",
        "\n",
        "# Configura√ß√µes de gera√ß√£o\n",
        "\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.6\n",
        "}\n",
        "\n",
        "# Configura√ß√µes de seguran√ßa\n",
        "\n",
        "safety_settings = {\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE'\n",
        "}\n",
        "\n",
        "# Instru√ß√µes de sistema\n",
        "\n",
        "system_instruction = \"\"\"\n",
        "Voc√™ √© uma assistente virtual para a Ouvidoria-Geral do Estado de Minas Gerais - OGE chamada Bel.\n",
        "Voc√™ deve buscar suas informa√ß√µes atrav√©s do site https://www.ouvidoriageral.mg.gov.br/, bem como demais legisla√ß√µes pertinentes ao Governo do Estado de Minas Gerais.\n",
        "Voc√™ deve ser sempre cordial, e utilizar linguagem simples em sua resposta.\n",
        "Voc√™ recebe em seu prompt uma manifesta√ß√£o ou uma d√∫vida de um cidad√£o.\n",
        "Voc√™ deve avaliar se a tratativa desta manifesta√ß√£o √© de compet√™ncia do Governo do Estado de Minas Gerais, ou compet√™ncia diversa, indicando o canal correto para manifestar.\n",
        "Caso seja compet√™ncia do Estado de Minas Gerais, voc√™ deve indicar qual a Ouvidoria Tem√°tica da OGE que deve tratar esta manifesta√ß√£o.\n",
        "As Ouvidorias Tem√°ticas dispon√≠veis s√£o:\n",
        "* Ouvidoria Ambiental e Agropecu√°ria;\n",
        "* Ouvidoria Educacional;\n",
        "* Ouvidoria de Fazenda, Licita√ß√µes e Patrim√¥nio P√∫blico;\n",
        "* Ouvidoria do Sistema Penitenci√°rio e Socioeducativo;\n",
        "* Ouvidoria de Pol√≠cia, subdividida entre as seguintes Assessorias: Pol√≠cia Militar de Minas Gerais, Pol√≠cia Civil de Minas Gerais, Corpo de Bombeiros Militares de Minas Gerais;\n",
        "* Ouvidoria de Sa√∫de;\n",
        "* Ouvidoria de Preven√ß√£o e Combate ao Ass√©dio Moral e Sexual;\n",
        "* Ouvidoria de Desenvolvimento Econ√¥mico, Infraestrutura e Desenvolvimento Social;\n",
        "* Ouvidoria de Preven√ß√£o e Combate √† Corrup√ß√£o.\n",
        "As tipologias de manifesta√ß√£o s√£o:\n",
        "* Den√∫ncia;\n",
        "* Reclama√ß√£o;\n",
        "* Solicita√ß√£o;\n",
        "* Sugest√£o;\n",
        "* Elogio;\n",
        "* Simplifique\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vHyZZyRGO9n6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo generativo conforme configura√ß√µes pr√©vias\n",
        "\n",
        "gen_model = genai.GenerativeModel(model_name = gen_model_name,\n",
        "                                  generation_config = generation_config,\n",
        "                                  safety_settings = safety_settings,\n",
        "                                  system_instruction = system_instruction)"
      ],
      "metadata": {
        "id": "4JDvO1TyPHw3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configura√ß√µes do Modelo Embedded"
      ],
      "metadata": {
        "id": "V--M81PoOsFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Listando os modelos embedding dispon√≠veis\n",
        "\n",
        "print('Modelos Embedding:\\n')\n",
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "PA1UECweOwje",
        "outputId": "81af132c-1e26-4bf1-bcd7-a4d11200674c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos Embedding:\n",
            "\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lembre-se de importar o arquivo \"Perguntas Frequentes.xlsx\" ao Google Colab antes de executar as etapas a seguir."
      ],
      "metadata": {
        "id": "VWvcEPwID696"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√£o do modelo\n",
        "\n",
        "emb_model_name = 'models/text-embedding-004'\n",
        "\n",
        "confianca_considerada = 0.75\n",
        "\n",
        "# Importando DataFrame de Perguntas Frequentes\n",
        "\n",
        "df = pd.read_excel('Perguntas Frequentes.xlsx')   # Arquivo disponibilizado no reposit√≥rio. Adicione ao Colab para execu√ß√£o.\n",
        "\n",
        "# Calculando Embeddings das quest√µes e respostas\n",
        "\n",
        "def embed_fn(title, text):\n",
        "  return genai.embed_content(model=emb_model_name,\n",
        "                             content=text,\n",
        "                             title=title,\n",
        "                             task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "df[\"Embeddings\"] = df.apply(lambda row: embed_fn(row[\"PERGUNTA\"], row[\"RESPOSTA\"]), axis=1)"
      ],
      "metadata": {
        "id": "xSK0R8M5PPLg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emb_model(prompt, base, model):\n",
        "  embeddings = genai.embed_content(model=model,\n",
        "                                   content=prompt,\n",
        "                                   task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  produtos_escalares = np.dot(np.stack(df[\"Embeddings\"]), embeddings)\n",
        "  confianca = max(produtos_escalares)\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "\n",
        "  return confianca, indice"
      ],
      "metadata": {
        "id": "6HPVdqt7VItc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicializa√ß√£o do Chatbot"
      ],
      "metadata": {
        "id": "6FXN1pqLQfqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_chat = gen_model.start_chat(history=[])\n",
        "\n",
        "prompt = input('Digite sua pergunta, ou escreva \"FIM\" para finalizar: ')\n",
        "\n",
        "while prompt.lower() != \"fim\":\n",
        "  confianca, indice = emb_model(prompt, df, emb_model_name)\n",
        "  if confianca >= confianca_considerada:\n",
        "    response = df.iloc[indice][\"RESPOSTA\"]\n",
        "  else:\n",
        "    response = gen_chat.send_message(prompt).text\n",
        "\n",
        "  print(f'\\nResposta: {response}\\n\\n')\n",
        "  prompt = input('Digite sua pergunta, ou escreva \"FIM\" para finalizar: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "QuQcxTT-QmTF",
        "outputId": "c3c9b202-68e6-4c15-a33c-31d7b9d5739a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite sua pergunta, ou escreva \"FIM\" para finalizar? O que compete a Ouvidoria Ambiental?\n",
            "\n",
            "Resposta: A Ouvidoria Ambiental e Agropecu√°ria promove a interlocu√ß√£o entre a Administra√ß√£o P√∫blica e o usu√°rio, recebendo e tratando reclama√ß√µes, den√∫ncias, elogios, solicita√ß√µes e sugest√µes relativas ao meio ambiente, saneamento b√°sico, agricultura e agropecu√°ria.\n",
            "\n",
            "\n",
            "Esperando prompt: Quero reclamar sobre uma semente podre que recebi da EMATER\n",
            "\n",
            "Resposta: Entendo sua frustra√ß√£o com a semente recebida da EMATER. Para te ajudar da melhor maneira poss√≠vel, voc√™ poderia me dizer qual a sua inten√ß√£o com essa reclama√ß√£o? Voc√™ gostaria de receber uma nova semente, denunciar a qualidade das sementes, ou apenas registrar sua insatisfa√ß√£o com o ocorrido? \n",
            "\n",
            "Com essa informa√ß√£o, posso te direcionar para a Ouvidoria mais adequada para tratar sua demanda. üòâ \n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: Quero receber uma nova semente\n",
            "\n",
            "Resposta: Ol√°! Para solicitar uma nova semente, recomendo que voc√™ entre em contato diretamente com a EMATER. A Ouvidoria-Geral do Estado atua em casos que envolvam falhas na presta√ß√£o de servi√ßos p√∫blicos, e a EMATER, apesar de ter v√≠nculo com o governo, √© uma empresa privada. \n",
            "\n",
            "Voc√™ pode buscar o escrit√≥rio da EMATER mais pr√≥ximo de voc√™ atrav√©s do site https://www.emater.mg.gov.br/ ou entrar em contato com eles por telefone. Espero ter ajudado! üòä \n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: O que √© uma reclama√ß√£o?\n",
            "\n",
            "Resposta: Demonstra√ß√£o de insatisfa√ß√£o relativa √† presta√ß√£o de servi√ßo p√∫blico e √† conduta de agentes p√∫blicos na presta√ß√£o e na fiscaliza√ß√£o do servi√ßo, como por exemplo: Detran (ve√≠culos removidos), Escolas p√∫blicas estaduais (matr√≠cula), Transporte intermunicipal (descumprimento do itiner√°rio), atua√ß√£o da PM (morosidade no atendimento), etc.\n",
            "\n",
            "\n",
            "Esperando prompt: Quero reclamar do valor do meu IPTU\n",
            "\n",
            "Resposta: Ol√°! A Ouvidoria-Geral do Estado de Minas Gerais n√£o tem compet√™ncia para tratar de assuntos relacionados ao IPTU, pois este √© um imposto municipal. \n",
            "\n",
            "Para registrar sua reclama√ß√£o sobre o valor do IPTU, recomendo que voc√™ procure a Prefeitura do seu munic√≠pio. \n",
            "\n",
            "Voc√™ pode encontrar os canais de atendimento da Prefeitura no site oficial do seu munic√≠pio. Espero ter ajudado! üòä \n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: fIm\n"
          ]
        }
      ]
    }
  ]
}